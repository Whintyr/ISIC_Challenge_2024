{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":3729,"sourceType":"modelInstanceVersion","modelInstanceId":2656,"modelId":312},{"sourceId":98867,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":82950,"modelId":107249}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":793.680734,"end_time":"2024-06-29T23:30:34.642937","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-29T23:17:20.962203","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"14f33eda98294bf7ab2c201ef8c071b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efc119d2e1e0456fa0a6593c16a85dc2","placeholder":"​","style":"IPY_MODEL_f4be4b7893f14d71a8658ad521e9d4e9","value":" 21.4M/21.4M [00:00&lt;00:00, 41.1MB/s]"}},"18bdb1a4a13e4aee9cc51601b980aca0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"244eb860d230481c85c8db4fd77fb99a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47503710d50a4aaba66bd273e31797b0","IPY_MODEL_938dc29705ca4174ab708b0e84ac456c","IPY_MODEL_14f33eda98294bf7ab2c201ef8c071b0"],"layout":"IPY_MODEL_18bdb1a4a13e4aee9cc51601b980aca0"}},"256368e0b8da40ffaab43806b6e7bdfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47503710d50a4aaba66bd273e31797b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1c7099741224d6d95e8f291dac107aa","placeholder":"​","style":"IPY_MODEL_e70b5a1f96bf4ddf9ac9271b3aa6ad1a","value":"model.safetensors: 100%"}},"938dc29705ca4174ab708b0e84ac456c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c198e83f65a043f6b6886c6984bf6303","max":21355344,"min":0,"orientation":"horizontal","style":"IPY_MODEL_256368e0b8da40ffaab43806b6e7bdfc","value":21355344}},"a1c7099741224d6d95e8f291dac107aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c198e83f65a043f6b6886c6984bf6303":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e70b5a1f96bf4ddf9ac9271b3aa6ad1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efc119d2e1e0456fa0a6593c16a85dc2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4be4b7893f14d71a8658ad521e9d4e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torcheval","metadata":{"papermill":{"duration":13.648463,"end_time":"2024-06-29T23:17:37.368242","exception":false,"start_time":"2024-06-29T23:17:23.719779","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:31:17.829688Z","iopub.execute_input":"2024-08-24T22:31:17.830030Z","iopub.status.idle":"2024-08-24T22:31:32.056980Z","shell.execute_reply.started":"2024-08-24T22:31:17.829991Z","shell.execute_reply":"2024-08-24T22:31:32.055872Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.12.2)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom matplotlib import pyplot as plt\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\nfrom torcheval.metrics.functional import binary_auroc\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold \n\n# For Image Models\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"papermill":{"duration":9.086974,"end_time":"2024-06-29T23:17:46.466572","exception":false,"start_time":"2024-06-29T23:17:37.379598","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:31:32.058751Z","iopub.execute_input":"2024-08-24T22:31:32.060162Z","iopub.status.idle":"2024-08-24T22:31:40.337890Z","shell.execute_reply.started":"2024-08-24T22:31:32.060104Z","shell.execute_reply":"2024-08-24T22:31:40.337083Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\n    \"seed\": 42,\n    \"epochs\": 5,\n    \"img_size\": 384,\n    \"model_name\": \"tf_efficientnet_b0_ns\",\n    \"checkpoint_path\" : \"/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b0/1/tf_efficientnet_b0_aa-827b6e33.pth\",\n    \"train_batch_size\": 32,\n    \"valid_batch_size\": 64,\n    \"learning_rate\": 1e-4,\n    \"scheduler\": 'CosineAnnealingLR',\n    \"min_lr\": 1e-6,\n    \"T_max\": 500,\n    \"weight_decay\": 1e-6,\n    \"fold\" : 0,\n    \"n_fold\": 5,\n    \"n_accumulate\": 1,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n}","metadata":{"papermill":{"duration":0.07116,"end_time":"2024-06-29T23:17:46.571192","exception":false,"start_time":"2024-06-29T23:17:46.500032","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:31:47.635426Z","iopub.execute_input":"2024-08-24T22:31:47.635957Z","iopub.status.idle":"2024-08-24T22:31:47.666155Z","shell.execute_reply.started":"2024-08-24T22:31:47.635922Z","shell.execute_reply":"2024-08-24T22:31:47.665023Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","metadata":{"papermill":{"duration":0.021715,"end_time":"2024-06-29T23:17:46.625274","exception":false,"start_time":"2024-06-29T23:17:46.603559","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:31:52.950705Z","iopub.execute_input":"2024-08-24T22:31:52.951502Z","iopub.status.idle":"2024-08-24T22:31:52.968277Z","shell.execute_reply.started":"2024-08-24T22:31:52.951438Z","shell.execute_reply":"2024-08-24T22:31:52.967161Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = \"/kaggle/input/isic-2024-challenge\"\nTRAIN_DIR = f'{ROOT_DIR}/train-image/image'","metadata":{"papermill":{"duration":0.017083,"end_time":"2024-06-29T23:17:46.653209","exception":false,"start_time":"2024-06-29T23:17:46.636126","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:31:53.805648Z","iopub.execute_input":"2024-08-24T22:31:53.806653Z","iopub.status.idle":"2024-08-24T22:31:53.811173Z","shell.execute_reply.started":"2024-08-24T22:31:53.806599Z","shell.execute_reply":"2024-08-24T22:31:53.810090Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(image_id):\n    return f\"{TRAIN_DIR}/{image_id}.jpg\"","metadata":{"papermill":{"duration":0.017155,"end_time":"2024-06-29T23:17:46.681165","exception":false,"start_time":"2024-06-29T23:17:46.66401","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:31:55.265226Z","iopub.execute_input":"2024-08-24T22:31:55.265603Z","iopub.status.idle":"2024-08-24T22:31:55.269878Z","shell.execute_reply.started":"2024-08-24T22:31:55.265562Z","shell.execute_reply":"2024-08-24T22:31:55.268935Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_images = sorted(glob.glob(f\"{TRAIN_DIR}/*.jpg\"))","metadata":{"papermill":{"duration":4.053439,"end_time":"2024-06-29T23:17:50.766866","exception":false,"start_time":"2024-06-29T23:17:46.713427","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:32:25.575429Z","iopub.execute_input":"2024-08-24T22:32:25.575811Z","iopub.status.idle":"2024-08-24T22:32:30.347772Z","shell.execute_reply.started":"2024-08-24T22:32:25.575773Z","shell.execute_reply":"2024-08-24T22:32:30.346863Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f\"{ROOT_DIR}/train-metadata.csv\")\n\nprint(\"        df.shape, # of positive cases, # of patients\")\nprint(\"original>\", df.shape, df.target.sum(), df[\"patient_id\"].unique().shape)\n \ndf_positive = df[df[\"target\"] == 1].reset_index(drop=True)\ndf_negative = df[df[\"target\"] == 0].reset_index(drop=True)\n\nprint(\"filtered>\", df.shape, df.target.sum(), df[\"patient_id\"].unique().shape)\n\ndf['file_path'] = df['isic_id'].apply(get_train_file_path)\ndf = df[ df[\"file_path\"].isin(train_images) ].reset_index(drop=True)\ndf","metadata":{"papermill":{"duration":7.631613,"end_time":"2024-06-29T23:17:58.409773","exception":false,"start_time":"2024-06-29T23:17:50.77816","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:32:30.349298Z","iopub.execute_input":"2024-08-24T22:32:30.349620Z","iopub.status.idle":"2024-08-24T22:32:36.964655Z","shell.execute_reply.started":"2024-08-24T22:32:30.349587Z","shell.execute_reply":"2024-08-24T22:32:36.963531Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"        df.shape, # of positive cases, # of patients\noriginal> (401059, 55) 393 (1042,)\nfiltered> (401059, 55) 393 (1042,)\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"             isic_id  target  patient_id  age_approx     sex  \\\n0       ISIC_0015670       0  IP_1235828        60.0    male   \n1       ISIC_0015845       0  IP_8170065        60.0    male   \n2       ISIC_0015864       0  IP_6724798        60.0    male   \n3       ISIC_0015902       0  IP_4111386        65.0    male   \n4       ISIC_0024200       0  IP_8313778        55.0    male   \n...              ...     ...         ...         ...     ...   \n401054  ISIC_9999937       0  IP_1140263        70.0    male   \n401055  ISIC_9999951       0  IP_5678181        60.0    male   \n401056  ISIC_9999960       0  IP_0076153        65.0  female   \n401057  ISIC_9999964       0  IP_5231513        30.0  female   \n401058  ISIC_9999967       0  IP_6426047        50.0    male   \n\n       anatom_site_general  clin_size_long_diam_mm          image_type  \\\n0          lower extremity                    3.04  TBP tile: close-up   \n1                head/neck                    1.10  TBP tile: close-up   \n2          posterior torso                    3.40  TBP tile: close-up   \n3           anterior torso                    3.22  TBP tile: close-up   \n4           anterior torso                    2.73  TBP tile: close-up   \n...                    ...                     ...                 ...   \n401054      anterior torso                    6.80  TBP tile: close-up   \n401055     posterior torso                    3.11  TBP tile: close-up   \n401056      anterior torso                    2.05  TBP tile: close-up   \n401057      anterior torso                    2.80  TBP tile: close-up   \n401058     lower extremity                    3.30  TBP tile: close-up   \n\n       tbp_tile_type   tbp_lv_A  ...  iddx_full  iddx_1  iddx_2  iddx_3  \\\n0          3D: white  20.244422  ...     Benign  Benign     NaN     NaN   \n1          3D: white  31.712570  ...     Benign  Benign     NaN     NaN   \n2             3D: XP  22.575830  ...     Benign  Benign     NaN     NaN   \n3             3D: XP  14.242329  ...     Benign  Benign     NaN     NaN   \n4          3D: white  24.725520  ...     Benign  Benign     NaN     NaN   \n...              ...        ...  ...        ...     ...     ...     ...   \n401054        3D: XP  22.574335  ...     Benign  Benign     NaN     NaN   \n401055     3D: white  19.977640  ...     Benign  Benign     NaN     NaN   \n401056        3D: XP  17.332567  ...     Benign  Benign     NaN     NaN   \n401057        3D: XP  22.288570  ...     Benign  Benign     NaN     NaN   \n401058        3D: XP  16.792900  ...     Benign  Benign     NaN     NaN   \n\n        iddx_4  iddx_5  mel_mitotic_index  mel_thick_mm  \\\n0          NaN     NaN                NaN           NaN   \n1          NaN     NaN                NaN           NaN   \n2          NaN     NaN                NaN           NaN   \n3          NaN     NaN                NaN           NaN   \n4          NaN     NaN                NaN           NaN   \n...        ...     ...                ...           ...   \n401054     NaN     NaN                NaN           NaN   \n401055     NaN     NaN                NaN           NaN   \n401056     NaN     NaN                NaN           NaN   \n401057     NaN     NaN                NaN           NaN   \n401058     NaN     NaN                NaN           NaN   \n\n        tbp_lv_dnn_lesion_confidence  \\\n0                          97.517282   \n1                           3.141455   \n2                          99.804040   \n3                          99.989998   \n4                          70.442510   \n...                              ...   \n401054                     99.999988   \n401055                     99.999820   \n401056                     99.999416   \n401057                    100.000000   \n401058                     99.999960   \n\n                                                file_path  \n0       /kaggle/input/isic-2024-challenge/train-image/...  \n1       /kaggle/input/isic-2024-challenge/train-image/...  \n2       /kaggle/input/isic-2024-challenge/train-image/...  \n3       /kaggle/input/isic-2024-challenge/train-image/...  \n4       /kaggle/input/isic-2024-challenge/train-image/...  \n...                                                   ...  \n401054  /kaggle/input/isic-2024-challenge/train-image/...  \n401055  /kaggle/input/isic-2024-challenge/train-image/...  \n401056  /kaggle/input/isic-2024-challenge/train-image/...  \n401057  /kaggle/input/isic-2024-challenge/train-image/...  \n401058  /kaggle/input/isic-2024-challenge/train-image/...  \n\n[401059 rows x 56 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>target</th>\n      <th>patient_id</th>\n      <th>age_approx</th>\n      <th>sex</th>\n      <th>anatom_site_general</th>\n      <th>clin_size_long_diam_mm</th>\n      <th>image_type</th>\n      <th>tbp_tile_type</th>\n      <th>tbp_lv_A</th>\n      <th>...</th>\n      <th>iddx_full</th>\n      <th>iddx_1</th>\n      <th>iddx_2</th>\n      <th>iddx_3</th>\n      <th>iddx_4</th>\n      <th>iddx_5</th>\n      <th>mel_mitotic_index</th>\n      <th>mel_thick_mm</th>\n      <th>tbp_lv_dnn_lesion_confidence</th>\n      <th>file_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0015670</td>\n      <td>0</td>\n      <td>IP_1235828</td>\n      <td>60.0</td>\n      <td>male</td>\n      <td>lower extremity</td>\n      <td>3.04</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: white</td>\n      <td>20.244422</td>\n      <td>...</td>\n      <td>Benign</td>\n      <td>Benign</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>97.517282</td>\n      <td>/kaggle/input/isic-2024-challenge/train-image/...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015845</td>\n      <td>0</td>\n      <td>IP_8170065</td>\n      <td>60.0</td>\n      <td>male</td>\n      <td>head/neck</td>\n      <td>1.10</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: white</td>\n      <td>31.712570</td>\n      <td>...</td>\n      <td>Benign</td>\n      <td>Benign</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.141455</td>\n      <td>/kaggle/input/isic-2024-challenge/train-image/...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0015864</td>\n      <td>0</td>\n      <td>IP_6724798</td>\n      <td>60.0</td>\n      <td>male</td>\n      <td>posterior torso</td>\n      <td>3.40</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>22.575830</td>\n      <td>...</td>\n      <td>Benign</td>\n      <td>Benign</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.804040</td>\n      <td>/kaggle/input/isic-2024-challenge/train-image/...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0015902</td>\n      <td>0</td>\n      <td>IP_4111386</td>\n      <td>65.0</td>\n      <td>male</td>\n      <td>anterior torso</td>\n      <td>3.22</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>14.242329</td>\n      <td>...</td>\n      <td>Benign</td>\n      <td>Benign</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.989998</td>\n      <td>/kaggle/input/isic-2024-challenge/train-image/...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0024200</td>\n      <td>0</td>\n      <td>IP_8313778</td>\n      <td>55.0</td>\n      <td>male</td>\n      <td>anterior torso</td>\n      <td>2.73</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: white</td>\n      <td>24.725520</td>\n      <td>...</td>\n      <td>Benign</td>\n      <td>Benign</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>70.442510</td>\n      <td>/kaggle/input/isic-2024-challenge/train-image/...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>401054</th>\n      <td>ISIC_9999937</td>\n      <td>0</td>\n      <td>IP_1140263</td>\n      <td>70.0</td>\n      <td>male</td>\n      <td>anterior torso</td>\n      <td>6.80</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>22.574335</td>\n      <td>...</td>\n      <td>Benign</td>\n      <td>Benign</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.999988</td>\n      <td>/kaggle/input/isic-2024-challenge/train-image/...</td>\n    </tr>\n    <tr>\n      <th>401055</th>\n      <td>ISIC_9999951</td>\n      <td>0</td>\n      <td>IP_5678181</td>\n      <td>60.0</td>\n      <td>male</td>\n      <td>posterior torso</td>\n      <td>3.11</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: white</td>\n      <td>19.977640</td>\n      <td>...</td>\n      <td>Benign</td>\n      <td>Benign</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.999820</td>\n      <td>/kaggle/input/isic-2024-challenge/train-image/...</td>\n    </tr>\n    <tr>\n      <th>401056</th>\n      <td>ISIC_9999960</td>\n      <td>0</td>\n      <td>IP_0076153</td>\n      <td>65.0</td>\n      <td>female</td>\n      <td>anterior torso</td>\n      <td>2.05</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>17.332567</td>\n      <td>...</td>\n      <td>Benign</td>\n      <td>Benign</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.999416</td>\n      <td>/kaggle/input/isic-2024-challenge/train-image/...</td>\n    </tr>\n    <tr>\n      <th>401057</th>\n      <td>ISIC_9999964</td>\n      <td>0</td>\n      <td>IP_5231513</td>\n      <td>30.0</td>\n      <td>female</td>\n      <td>anterior torso</td>\n      <td>2.80</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>22.288570</td>\n      <td>...</td>\n      <td>Benign</td>\n      <td>Benign</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.000000</td>\n      <td>/kaggle/input/isic-2024-challenge/train-image/...</td>\n    </tr>\n    <tr>\n      <th>401058</th>\n      <td>ISIC_9999967</td>\n      <td>0</td>\n      <td>IP_6426047</td>\n      <td>50.0</td>\n      <td>male</td>\n      <td>lower extremity</td>\n      <td>3.30</td>\n      <td>TBP tile: close-up</td>\n      <td>3D: XP</td>\n      <td>16.792900</td>\n      <td>...</td>\n      <td>Benign</td>\n      <td>Benign</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.999960</td>\n      <td>/kaggle/input/isic-2024-challenge/train-image/...</td>\n    </tr>\n  </tbody>\n</table>\n<p>401059 rows × 56 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape[0], df.target.sum()","metadata":{"papermill":{"duration":0.020088,"end_time":"2024-06-29T23:17:58.441777","exception":false,"start_time":"2024-06-29T23:17:58.421689","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:32:36.967394Z","iopub.execute_input":"2024-08-24T22:32:36.967782Z","iopub.status.idle":"2024-08-24T22:32:36.975243Z","shell.execute_reply.started":"2024-08-24T22:32:36.967745Z","shell.execute_reply":"2024-08-24T22:32:36.974196Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(401059, 393)"},"metadata":{}}]},{"cell_type":"code","source":"CONFIG['T_max'] = df.shape[0] * (CONFIG[\"n_fold\"]-1) * CONFIG['epochs'] // CONFIG['train_batch_size'] // CONFIG[\"n_fold\"]\nCONFIG['T_max']","metadata":{"papermill":{"duration":0.020234,"end_time":"2024-06-29T23:17:58.473737","exception":false,"start_time":"2024-06-29T23:17:58.453503","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:32:39.305400Z","iopub.execute_input":"2024-08-24T22:32:39.305779Z","iopub.status.idle":"2024-08-24T22:32:39.312334Z","shell.execute_reply.started":"2024-08-24T22:32:39.305742Z","shell.execute_reply":"2024-08-24T22:32:39.311485Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"50132"},"metadata":{}}]},{"cell_type":"code","source":"sgkf = StratifiedGroupKFold(n_splits=CONFIG['n_fold'])\n\nfor fold, ( _, val_) in enumerate(sgkf.split(df, df.target,df.patient_id)):\n      df.loc[val_ , \"kfold\"] = int(fold)","metadata":{"papermill":{"duration":0.466594,"end_time":"2024-06-29T23:17:58.975943","exception":false,"start_time":"2024-06-29T23:17:58.509349","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T22:32:42.175472Z","iopub.execute_input":"2024-08-24T22:32:42.175868Z","iopub.status.idle":"2024-08-24T22:32:44.373650Z","shell.execute_reply.started":"2024-08-24T22:32:42.175829Z","shell.execute_reply":"2024-08-24T22:32:44.372783Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class ISICDataset_for_Train(Dataset):\n    def __init__(self, df, transforms=None):\n        # Split the positive samples into training and validation sets\n        df_positive = df[df[\"target\"] == 1].reset_index(drop=True)\n        df_positive_train = df_positive.iloc[:-50]\n        df_negative_train = df_negative.iloc[:-50]\n        \n        self.df_train = pd.concat([df_positive_train, df_negative_train]).reset_index(drop=True)\n        self.file_names = self.df_train['file_path'].values\n        self.targets = self.df_train['target'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df_train)\n    \n    def __getitem__(self, index):\n        img_path = self.file_names[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        target = self.targets[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return {\n            'image': img,\n            'target': target\n        }\n\nclass ISICDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        df_positive_val = df_positive.iloc[-50:]\n        df_negative_val = df_negative.iloc[-50:]\n        self.df_val = pd.concat([df_positive_val, df_negative_val]).reset_index(drop=True)\n        self.file_names = self.df_val['file_path'].values\n        self.targets = self.df_val['target'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df_val)\n    \n    def __getitem__(self, index):\n        img_path = self.file_names[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        target = self.targets[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return {\n            'image': img,\n            'target': target\n        }","metadata":{"papermill":{"duration":0.027666,"end_time":"2024-06-29T23:17:59.039604","exception":false,"start_time":"2024-06-29T23:17:59.011938","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:18.816280Z","iopub.execute_input":"2024-08-24T07:50:18.816681Z","iopub.status.idle":"2024-08-24T07:50:18.843996Z","shell.execute_reply.started":"2024-08-24T07:50:18.816638Z","shell.execute_reply":"2024-08-24T07:50:18.843038Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    \"train\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.RandomRotate90(p=0.5),\n        A.Flip(p=0.5),\n        A.Downscale(p=0.25),\n        A.ShiftScaleRotate(shift_limit=0.1, \n                           scale_limit=0.15, \n                           rotate_limit=60, \n                           p=0.5),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.),\n    \n    \"valid\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.)\n}","metadata":{"papermill":{"duration":0.023138,"end_time":"2024-06-29T23:17:59.09779","exception":false,"start_time":"2024-06-29T23:17:59.074652","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:18.845255Z","iopub.execute_input":"2024-08-24T07:50:18.845583Z","iopub.status.idle":"2024-08-24T07:50:18.863135Z","shell.execute_reply.started":"2024-08-24T07:50:18.845552Z","shell.execute_reply":"2024-08-24T07:50:18.862052Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"class GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        self.p = nn.Parameter(torch.ones(1)*p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n        \n    def gem(self, x, p=3, eps=1e-6):\n        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n        \n    def __repr__(self):\n        return self.__class__.__name__ + \\\n                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n                ', ' + 'eps=' + str(self.eps) + ')'","metadata":{"papermill":{"duration":0.02223,"end_time":"2024-06-29T23:17:59.155728","exception":false,"start_time":"2024-06-29T23:17:59.133498","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:18.864178Z","iopub.execute_input":"2024-08-24T07:50:18.864513Z","iopub.status.idle":"2024-08-24T07:50:18.876841Z","shell.execute_reply.started":"2024-08-24T07:50:18.864479Z","shell.execute_reply":"2024-08-24T07:50:18.875907Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class ISICModel(nn.Module):\n    def __init__(self, model_name, num_classes=1, pretrained=False, checkpoint_path=None):\n        super(ISICModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n\n        in_features = self.model.classifier.in_features\n        self.model.classifier = nn.Identity()\n        self.model.global_pool = nn.Identity()\n        self.pooling = GeM()\n        self.linear = nn.Linear(in_features, num_classes)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, images):\n        features = self.model(images)\n        pooled_features = self.pooling(features).flatten(1)\n        output = self.sigmoid(self.linear(pooled_features))\n        return output\n\n    \nmodel = ISICModel(CONFIG['model_name'], checkpoint_path=CONFIG['checkpoint_path'])\nmodel.to(CONFIG['device'])","metadata":{"papermill":{"duration":1.183958,"end_time":"2024-06-29T23:18:00.375162","exception":false,"start_time":"2024-06-29T23:17:59.191204","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Loss Function</h1></span>","metadata":{"papermill":{"duration":0.012134,"end_time":"2024-06-29T23:18:00.400146","exception":false,"start_time":"2024-06-29T23:18:00.388012","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def criterion(outputs, targets):\n    return nn.BCELoss()(outputs, targets)","metadata":{"papermill":{"duration":0.020023,"end_time":"2024-06-29T23:18:00.432262","exception":false,"start_time":"2024-06-29T23:18:00.412239","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:19.063792Z","iopub.execute_input":"2024-08-24T07:50:19.064136Z","iopub.status.idle":"2024-08-24T07:50:19.068472Z","shell.execute_reply.started":"2024-08-24T07:50:19.064103Z","shell.execute_reply":"2024-08-24T07:50:19.067472Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    running_auroc  = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        images = data['image'].to(device, dtype=torch.float)\n        targets = data['target'].to(device, dtype=torch.float)\n        \n        batch_size = images.size(0)\n        \n        outputs = model(images).squeeze()\n        loss = criterion(outputs, targets)\n        loss = loss / CONFIG['n_accumulate']\n            \n        loss.backward()\n    \n        if (step + 1) % CONFIG['n_accumulate'] == 0:\n            optimizer.step()\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            if scheduler is not None:\n                scheduler.step()\n                \n        auroc = binary_auroc(input=outputs.squeeze(), target=targets).item()\n        \n        running_loss += (loss.item() * batch_size)\n        running_auroc  += (auroc * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        epoch_auroc = running_auroc / dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, Train_Auroc=epoch_auroc,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss, epoch_auroc","metadata":{"papermill":{"duration":0.024329,"end_time":"2024-06-29T23:18:00.493233","exception":false,"start_time":"2024-06-29T23:18:00.468904","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:19.069595Z","iopub.execute_input":"2024-08-24T07:50:19.069872Z","iopub.status.idle":"2024-08-24T07:50:19.082219Z","shell.execute_reply.started":"2024-08-24T07:50:19.069841Z","shell.execute_reply":"2024-08-24T07:50:19.081306Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"@torch.inference_mode()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    running_auroc = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:        \n        images = data['image'].to(device, dtype=torch.float)\n        targets = data['target'].to(device, dtype=torch.float)\n        \n        batch_size = images.size(0)\n        outputs = model(images).squeeze()\n        loss = criterion(outputs, targets)\n\n        auroc = binary_auroc(input=outputs.squeeze(), target=targets).item()\n        running_loss += (loss.item() * batch_size)\n        running_auroc  += (auroc * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        epoch_auroc = running_auroc / dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss, Valid_Auroc=epoch_auroc,\n                        LR=optimizer.param_groups[0]['lr'])   \n    \n    gc.collect()\n    \n    return epoch_loss, epoch_auroc","metadata":{"papermill":{"duration":0.02315,"end_time":"2024-06-29T23:18:00.551972","exception":false,"start_time":"2024-06-29T23:18:00.528822","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:19.083608Z","iopub.execute_input":"2024-08-24T07:50:19.083926Z","iopub.status.idle":"2024-08-24T07:50:19.097484Z","shell.execute_reply.started":"2024-08-24T07:50:19.083890Z","shell.execute_reply":"2024-08-24T07:50:19.096037Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs):\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_auroc = -np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1): \n        gc.collect()\n        train_epoch_loss, train_epoch_auroc = train_one_epoch(model, optimizer, scheduler, \n                                           dataloader=train_loader, \n                                           device=CONFIG['device'], epoch=epoch)\n        \n        val_epoch_loss, val_epoch_auroc = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n                                         epoch=epoch)\n    \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(val_epoch_loss)\n        history['Train AUROC'].append(train_epoch_auroc)\n        history['Valid AUROC'].append(val_epoch_auroc)\n        history['lr'].append( scheduler.get_lr()[0] )\n        \n        # deep copy the model\n        if best_epoch_auroc <= val_epoch_auroc:\n            print(f\"{b_}Validation AUROC Improved ({best_epoch_auroc} ---> {val_epoch_auroc})\")\n            best_epoch_auroc = val_epoch_auroc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"AUROC{:.4f}_Loss{:.4f}_epoch{:.0f}.bin\".format(val_epoch_auroc, val_epoch_loss, epoch)\n            torch.save(model.state_dict(), PATH)\n            # Save a model file from the current directory\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n    \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best AUROC: {:.4f}\".format(best_epoch_auroc))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"papermill":{"duration":0.026227,"end_time":"2024-06-29T23:18:00.614057","exception":false,"start_time":"2024-06-29T23:18:00.58783","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:19.100263Z","iopub.execute_input":"2024-08-24T07:50:19.100614Z","iopub.status.idle":"2024-08-24T07:50:19.115025Z","shell.execute_reply.started":"2024-08-24T07:50:19.100575Z","shell.execute_reply":"2024-08-24T07:50:19.114130Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n                                                   eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n                                                             eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == None:\n        return None\n        \n    return scheduler","metadata":{"papermill":{"duration":0.020426,"end_time":"2024-06-29T23:18:00.646386","exception":false,"start_time":"2024-06-29T23:18:00.62596","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:19.116212Z","iopub.execute_input":"2024-08-24T07:50:19.116562Z","iopub.status.idle":"2024-08-24T07:50:19.128102Z","shell.execute_reply.started":"2024-08-24T07:50:19.116526Z","shell.execute_reply":"2024-08-24T07:50:19.127224Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(df, fold):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    train_dataset = ISICDataset_for_Train(df_train, transforms=data_transforms[\"train\"])\n    valid_dataset = ISICDataset(df_valid, transforms=data_transforms[\"valid\"])\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=2, shuffle=False, pin_memory=True)\n    \n    return train_loader, valid_loader","metadata":{"papermill":{"duration":0.02047,"end_time":"2024-06-29T23:18:00.678761","exception":false,"start_time":"2024-06-29T23:18:00.658291","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:19.129332Z","iopub.execute_input":"2024-08-24T07:50:19.129662Z","iopub.status.idle":"2024-08-24T07:50:19.142487Z","shell.execute_reply.started":"2024-08-24T07:50:19.129629Z","shell.execute_reply":"2024-08-24T07:50:19.141563Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Prepare Dataloaders</span>","metadata":{"papermill":{"duration":0.011803,"end_time":"2024-06-29T23:18:00.702461","exception":false,"start_time":"2024-06-29T23:18:00.690658","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_loader, valid_loader = prepare_loaders(df, fold=CONFIG[\"fold\"])","metadata":{"papermill":{"duration":0.033503,"end_time":"2024-06-29T23:18:00.747996","exception":false,"start_time":"2024-06-29T23:18:00.714493","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:19.143589Z","iopub.execute_input":"2024-08-24T07:50:19.143898Z","iopub.status.idle":"2024-08-24T07:50:20.093587Z","shell.execute_reply.started":"2024-08-24T07:50:19.143853Z","shell.execute_reply":"2024-08-24T07:50:20.092738Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Define Optimizer and Scheduler</span>","metadata":{"papermill":{"duration":0.012164,"end_time":"2024-06-29T23:18:00.772504","exception":false,"start_time":"2024-06-29T23:18:00.76034","status":"completed"},"tags":[]}},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n                       weight_decay=CONFIG['weight_decay'])\nscheduler = fetch_scheduler(optimizer)","metadata":{"papermill":{"duration":0.021007,"end_time":"2024-06-29T23:18:00.805494","exception":false,"start_time":"2024-06-29T23:18:00.784487","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:20.094808Z","iopub.execute_input":"2024-08-24T07:50:20.095165Z","iopub.status.idle":"2024-08-24T07:50:20.101890Z","shell.execute_reply.started":"2024-08-24T07:50:20.095128Z","shell.execute_reply":"2024-08-24T07:50:20.100890Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Start Training</span>","metadata":{"papermill":{"duration":0.011766,"end_time":"2024-06-29T23:18:00.872059","exception":false,"start_time":"2024-06-29T23:18:00.860293","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model, history = run_training(model, optimizer, scheduler,\n                              device=CONFIG['device'],\n                              num_epochs=CONFIG['epochs'])","metadata":{"papermill":{"duration":745.635338,"end_time":"2024-06-29T23:30:26.519348","exception":false,"start_time":"2024-06-29T23:18:00.88401","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-24T07:50:20.103187Z","iopub.execute_input":"2024-08-24T07:50:20.103559Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[INFO] Using GPU: Tesla P100-PCIE-16GB\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10024/10024 [1:00:17<00:00,  2.77it/s, Epoch=1, LR=9.06e-5, Train_Auroc=0.508, Train_Loss=0.00673]\n100%|██████████| 1/1 [00:00<00:00,  1.27it/s, Epoch=1, LR=9.06e-5, Valid_Auroc=0.5, Valid_Loss=5.16]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34mValidation AUROC Improved (-inf ---> 0.5)\nModel Saved\u001b[0m\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10024/10024 [1:00:20<00:00,  2.77it/s, Epoch=2, LR=6.58e-5, Train_Auroc=0.51, Train_Loss=0.00571]\n100%|██████████| 1/1 [00:00<00:00,  1.52it/s, Epoch=2, LR=6.58e-5, Valid_Auroc=0.5, Valid_Loss=5.76]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34mValidation AUROC Improved (0.5 ---> 0.5)\nModel Saved\u001b[0m\n\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 2739/10024 [16:39<44:59,  2.70it/s, Epoch=3, LR=5.75e-5, Train_Auroc=0.511, Train_Loss=0.00537] ","output_type":"stream"}]},{"cell_type":"code","source":"history = pd.DataFrame.from_dict(history)\nhistory.to_csv(\"history.csv\", index=False)","metadata":{"papermill":{"duration":0.408452,"end_time":"2024-06-29T23:30:27.325321","exception":false,"start_time":"2024-06-29T23:30:26.916869","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(history.shape[0]), history[\"Train Loss\"].values, label=\"Train Loss\")\nplt.plot( range(history.shape[0]), history[\"Valid Loss\"].values, label=\"Valid Loss\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Loss\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":0.673512,"end_time":"2024-06-29T23:30:29.236485","exception":false,"start_time":"2024-06-29T23:30:28.562973","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(history.shape[0]), history[\"Train AUROC\"].values, label=\"Train AUROC\")\nplt.plot( range(history.shape[0]), history[\"Valid AUROC\"].values, label=\"Valid AUROC\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"AUROC\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":0.648584,"end_time":"2024-06-29T23:30:30.277915","exception":false,"start_time":"2024-06-29T23:30:29.629331","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(history.shape[0]), history[\"lr\"].values, label=\"lr\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"lr\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":0.617692,"end_time":"2024-06-29T23:30:31.290602","exception":false,"start_time":"2024-06-29T23:30:30.67291","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}